{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"Implementation/","text":"Implementation The task begins with starting the Gazebo Environment along with Rviz. Gazebo is the environment where the entire simulation would take place while Rviz is the window that we have used to monitor the movement of the UR_5 arms and the collisions of various elements used in this task. The first component to get activated is the 2D camera (Cam1 in our codes). This camera detects not only the number of packages but also their QR codes from where we can get the details of the package (Item, SKU, location, Priority etc.) This camera is then to detect 9 of 12 packages, instead of which we have opted to detect all 12 of the packages in the shelf. The reason to detect all packages was to get the location of all packages and trying out faster trajectories by trial and error. As soon as the packages are detected the IMS Inventory sheet is updated of all the detected packages. This is done by subscribing to the MQTT client A total of 9 orders are published after one minute of Simulation time, each republished on a unique ID Then we process the orders according to the priority order (Red- Yellow- Green) and place the corresponding packages on the conveyor. Once the package is placed on the conveyor belt by UR5_1 the \u2018Order Dispatched\u2019 sheet is updated and an Email of the order being dispatched is sent. The package placed on the conveyor belt is then picked by UR5_2 once it comes into the field of vision of Logical Camera_2 It then gets sorted into its respective bin followed by another email being sent of the order getting delivered. Additionally, the \u2018Order Shipped\u2019 sheet is update in the IMS which keeps track of all the orders shipped and their time. The WMS sheet is update simultaneously throughout the task which acts as a Summary sheet of the IMS also called the Dashboard. This used to reflect on the real-time values.","title":"Implementation"},{"location":"Implementation/#implementation","text":"The task begins with starting the Gazebo Environment along with Rviz. Gazebo is the environment where the entire simulation would take place while Rviz is the window that we have used to monitor the movement of the UR_5 arms and the collisions of various elements used in this task. The first component to get activated is the 2D camera (Cam1 in our codes). This camera detects not only the number of packages but also their QR codes from where we can get the details of the package (Item, SKU, location, Priority etc.) This camera is then to detect 9 of 12 packages, instead of which we have opted to detect all 12 of the packages in the shelf. The reason to detect all packages was to get the location of all packages and trying out faster trajectories by trial and error. As soon as the packages are detected the IMS Inventory sheet is updated of all the detected packages. This is done by subscribing to the MQTT client A total of 9 orders are published after one minute of Simulation time, each republished on a unique ID Then we process the orders according to the priority order (Red- Yellow- Green) and place the corresponding packages on the conveyor. Once the package is placed on the conveyor belt by UR5_1 the \u2018Order Dispatched\u2019 sheet is updated and an Email of the order being dispatched is sent. The package placed on the conveyor belt is then picked by UR5_2 once it comes into the field of vision of Logical Camera_2 It then gets sorted into its respective bin followed by another email being sent of the order getting delivered. Additionally, the \u2018Order Shipped\u2019 sheet is update in the IMS which keeps track of all the orders shipped and their time. The WMS sheet is update simultaneously throughout the task which acts as a Summary sheet of the IMS also called the Dashboard. This used to reflect on the real-time values.","title":"Implementation"},{"location":"Introduction/","text":"INTRODUCTION The theme for our project was Vargi bots. In this theme we are picking pakages from a shelf and segregating them into their respective bins. The task is carried out with two UR5 arms, two logical cameras, one 2D camera and conveyor belt. UR5 Arms These are used to carry out the pick and place functions. The packages are kept in a shelf from which they are supposed to be picked upon receiving an order. The picked package is then placed on the conveyor belt and sent towards the other Arm. The most important part to focus for this arm was the precision with which it would pick the package. The chances of collisions with external objects were high. If the package is not properly attached to the Vaccum Gripper it may collide with the shelf or other packages in it. Hence the trajectory set is such that it picks the package from the shelf and places it on the conveyor belt without any collision. It also ensures that the package is in perfect alignment with the vaccum gripper before it is turned on. The second UR5 Arm picks the packages from the conveyor belt and drops them into their respective bins. The chances of collisions are the greates in UR5 arms. We have tried our best to set a trajectory that would avoid any collision of the arm, with or without the package. While doing this we have not neglected the fact that time taken in making the drop is just as crucial. the trajectory used is collision free and the shortest one possible. Cameras The colour and QR code decoding(Computer Vision techniques) is done by the 2D camera located in front of the shelf, behind the first UR5 arm. This arm is responsible for recognizing the colour of the package and hence its priority. After receiving the order, this camera is used to ensure we have picked the right package. The two logical cameras are located above the conveyor belt in front of each UR5 arm. These cameras give only the package name ie., package001 etc. These cameras have been used by us to co-ordinate between the two UR5 arms as well as keeping a record of number of packages picked by the second arm.","title":"Introduction"},{"location":"Introduction/#introduction","text":"The theme for our project was Vargi bots. In this theme we are picking pakages from a shelf and segregating them into their respective bins. The task is carried out with two UR5 arms, two logical cameras, one 2D camera and conveyor belt.","title":"INTRODUCTION"},{"location":"Introduction/#ur5-arms","text":"These are used to carry out the pick and place functions. The packages are kept in a shelf from which they are supposed to be picked upon receiving an order. The picked package is then placed on the conveyor belt and sent towards the other Arm. The most important part to focus for this arm was the precision with which it would pick the package. The chances of collisions with external objects were high. If the package is not properly attached to the Vaccum Gripper it may collide with the shelf or other packages in it. Hence the trajectory set is such that it picks the package from the shelf and places it on the conveyor belt without any collision. It also ensures that the package is in perfect alignment with the vaccum gripper before it is turned on. The second UR5 Arm picks the packages from the conveyor belt and drops them into their respective bins. The chances of collisions are the greates in UR5 arms. We have tried our best to set a trajectory that would avoid any collision of the arm, with or without the package. While doing this we have not neglected the fact that time taken in making the drop is just as crucial. the trajectory used is collision free and the shortest one possible.","title":"UR5 Arms"},{"location":"Introduction/#cameras","text":"The colour and QR code decoding(Computer Vision techniques) is done by the 2D camera located in front of the shelf, behind the first UR5 arm. This arm is responsible for recognizing the colour of the package and hence its priority. After receiving the order, this camera is used to ensure we have picked the right package. The two logical cameras are located above the conveyor belt in front of each UR5 arm. These cameras give only the package name ie., package001 etc. These cameras have been used by us to co-ordinate between the two UR5 arms as well as keeping a record of number of packages picked by the second arm.","title":"Cameras"},{"location":"RQT_Graph/","text":"RQT Graph","title":"RQT Graph"},{"location":"RQT_Graph/#rqt-graph","text":"","title":"RQT Graph"},{"location":"about/","text":"Welcome to MkDocs For full documentation visit mkdocs.org . Commands of TP mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs help - Print this help message. Project layout mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files.","title":"About"},{"location":"about/#welcome-to-mkdocs","text":"For full documentation visit mkdocs.org .","title":"Welcome to MkDocs"},{"location":"about/#commands-of-tp","text":"mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs help - Print this help message.","title":"Commands of TP"},{"location":"about/#project-layout","text":"mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files.","title":"Project layout"}]}