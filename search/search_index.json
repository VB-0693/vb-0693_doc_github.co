{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Abstract Automation and Visualisation are taking over various aspects of day-to-day life. In order to reduce human errors and increase work efficiency, many industries are opting for automation. The theme for this year has been based on this realization. The current theme of e-Yantra 2020-21 is based on the visualization of Industry 4.0 wherein our theme, in particular, is called Vargi BOTS. The name takes its root from the Sanskrit word Vargikaran (\u0935\u0930\u094d\u0917\u0940\u0915\u0930\u0923) which means segregation. The theme is set in the abstraction of a warehouse management system designed in a 3D dynamic simulator, Gazebo which is used efficiently to simulate robots in complex environments. The arena used for this theme is an automated warehouse where we use two industrial robotic arms to pick and place the packages according to the orders received. As the theme draws its inspiration from Industry 4.0 it focuses heavily on automation. One of the arms is used to pick and place the packages on the conveyor belt. The other, placed at the end of the conveyor belt, is used to place the packages into their respective bins. Each bin represents a destination for the package. As the packages are sent out from the warehouse there will also be alerts sent to the user via email notifying them about the package being shipped from the warehouse. The challenge for the participants is that they have to deliver as many high-priority packages as possible. The controller is supposed to make smart decisions in order to finish the task efficiently. Along with decision-making, precision and collision avoidance is also equally important for the task to complete. YouTube Video [ ) UR5 Arms These are used to carry out the pick and place functions. The packages are kept in a shelf from which they are supposed to be picked upon receiving an order. The picked package is then placed on the conveyor belt and sent towards the other Arm. The most important part to focus for this arm was the precision with which it would pick the package. The chances of collisions with external objects were high. If the package is not properly attached to the Vaccum Gripper it may collide with the shelf or other packages in it. Hence the trajectory set is such that it picks the package from the shelf and places it on the conveyor belt without any collision. It also ensures that the package is in perfect alignment with the vaccum gripper before it is turned on. The second UR5 Arm picks the packages from the conveyor belt and drops them into their respective bins. The chances of collisions are the greates in UR5 arms. We have tried our best to set a trajectory that would avoid any collision of the arm, with or without the package. While doing this we have not neglected the fact that time taken in making the drop is just as crucial. the trajectory used is collision free and the shortest one possible. Cameras The colour and QR code decoding(Computer Vision techniques) is done by the 2D camera located in front of the shelf, behind the first UR5 arm. This arm is responsible for recognizing the colour of the package and hence its priority. After receiving the order, this camera is used to ensure we have picked the right package. The two logical cameras are located above the conveyor belt in front of each UR5 arm. These cameras give only the package name ie., package001 etc. These cameras have been used by us to co-ordinate between the two UR5 arms as well as keeping a record of number of packages picked by the second arm. Packages Red - High Priority Package The High Priority Package symbolizes packages such as medicines. Yellow - Medium Priority Package The Medium Priority Package symbolizes packages such as packaged food. Green - Low Priority Package The Low Priority Package symbolizes packages such as clothes. Implementation The task begins with starting the Gazebo Environment along with Rviz. Gazebo is the environment where the entire simulation would take place while Rviz is the window that we have used to monitor the movement of the UR5 arms and the collisions of various elements used in this task. The first component to get activated is the 2D camera (Cam1 in our codes). This camera detects not only the number of packages but also their QR codes from where we can get the details of the package (Item, SKU, location, Priority etc.) This camera is then to detect 9 of 12 packages, instead of which we have opted to detect all 12 of the packages in the shelf. The reason to detect all packages was to get the location of all packages and trying out faster trajectories by trial and error. As soon as the packages are detected the IMS Inventory sheet is updated of all the detected packages. This is done by subscribing to the MQTT client. MQTT client publishes the data to the Inventory sheet displaying the Timestamp and details of the package scanned from the 2D camera. A total of 9 orders are published after one minute of Simulation time, each republished on a unique ID. These orders are published randomly and at various intervals of time. The orders are sorted as the priority as soon as they are received. Then we process the orders according to the priority order (Red- Yellow- Green) and place the corresponding packages on the conveyor. Here, Logical Camera_1 placed at the top of the conveyor belt registers the package being placed as well but we have not made much use of this camera for our code. Once the package is placed on the conveyor belt by UR5_1 the \u2018Order Dispatched\u2019 sheet is updated and an Email of the order being dispatched is sent. This sheet is also a part of the IMS. The email address used for this task is the team ID account we have created for E-Yantra. The package placed on the conveyor belt is then picked by UR5_2 once it comes into the field of vision of Logical Camera_2. As soon as this camera registers the package arriving the conveyor belt is stopped till UR5_2 has picked up the package. It then gets sorted into its respective bin followed by another email being sent of the order getting delivered. Additionally, the \u2018Order Shipped\u2019 sheet is updated in the IMS which keeps track of all the orders shipped and their time. The WMS sheet is update simultaneously throughout the task which acts as a Summary sheet of the IMS also called the Dashboard. This used to reflect on the real-time values. RQT Graph","title":"Documentation"},{"location":"#abstract","text":"Automation and Visualisation are taking over various aspects of day-to-day life. In order to reduce human errors and increase work efficiency, many industries are opting for automation. The theme for this year has been based on this realization. The current theme of e-Yantra 2020-21 is based on the visualization of Industry 4.0 wherein our theme, in particular, is called Vargi BOTS. The name takes its root from the Sanskrit word Vargikaran (\u0935\u0930\u094d\u0917\u0940\u0915\u0930\u0923) which means segregation. The theme is set in the abstraction of a warehouse management system designed in a 3D dynamic simulator, Gazebo which is used efficiently to simulate robots in complex environments. The arena used for this theme is an automated warehouse where we use two industrial robotic arms to pick and place the packages according to the orders received. As the theme draws its inspiration from Industry 4.0 it focuses heavily on automation. One of the arms is used to pick and place the packages on the conveyor belt. The other, placed at the end of the conveyor belt, is used to place the packages into their respective bins. Each bin represents a destination for the package. As the packages are sent out from the warehouse there will also be alerts sent to the user via email notifying them about the package being shipped from the warehouse. The challenge for the participants is that they have to deliver as many high-priority packages as possible. The controller is supposed to make smart decisions in order to finish the task efficiently. Along with decision-making, precision and collision avoidance is also equally important for the task to complete.","title":"Abstract"},{"location":"#youtube-video","text":"[ )","title":"YouTube Video"},{"location":"#ur5-arms","text":"These are used to carry out the pick and place functions. The packages are kept in a shelf from which they are supposed to be picked upon receiving an order. The picked package is then placed on the conveyor belt and sent towards the other Arm. The most important part to focus for this arm was the precision with which it would pick the package. The chances of collisions with external objects were high. If the package is not properly attached to the Vaccum Gripper it may collide with the shelf or other packages in it. Hence the trajectory set is such that it picks the package from the shelf and places it on the conveyor belt without any collision. It also ensures that the package is in perfect alignment with the vaccum gripper before it is turned on. The second UR5 Arm picks the packages from the conveyor belt and drops them into their respective bins. The chances of collisions are the greates in UR5 arms. We have tried our best to set a trajectory that would avoid any collision of the arm, with or without the package. While doing this we have not neglected the fact that time taken in making the drop is just as crucial. the trajectory used is collision free and the shortest one possible.","title":"UR5 Arms"},{"location":"#cameras","text":"The colour and QR code decoding(Computer Vision techniques) is done by the 2D camera located in front of the shelf, behind the first UR5 arm. This arm is responsible for recognizing the colour of the package and hence its priority. After receiving the order, this camera is used to ensure we have picked the right package. The two logical cameras are located above the conveyor belt in front of each UR5 arm. These cameras give only the package name ie., package001 etc. These cameras have been used by us to co-ordinate between the two UR5 arms as well as keeping a record of number of packages picked by the second arm.","title":"Cameras"},{"location":"#packages","text":"Red - High Priority Package The High Priority Package symbolizes packages such as medicines. Yellow - Medium Priority Package The Medium Priority Package symbolizes packages such as packaged food. Green - Low Priority Package The Low Priority Package symbolizes packages such as clothes.","title":"Packages"},{"location":"#implementation","text":"The task begins with starting the Gazebo Environment along with Rviz. Gazebo is the environment where the entire simulation would take place while Rviz is the window that we have used to monitor the movement of the UR5 arms and the collisions of various elements used in this task. The first component to get activated is the 2D camera (Cam1 in our codes). This camera detects not only the number of packages but also their QR codes from where we can get the details of the package (Item, SKU, location, Priority etc.) This camera is then to detect 9 of 12 packages, instead of which we have opted to detect all 12 of the packages in the shelf. The reason to detect all packages was to get the location of all packages and trying out faster trajectories by trial and error. As soon as the packages are detected the IMS Inventory sheet is updated of all the detected packages. This is done by subscribing to the MQTT client. MQTT client publishes the data to the Inventory sheet displaying the Timestamp and details of the package scanned from the 2D camera. A total of 9 orders are published after one minute of Simulation time, each republished on a unique ID. These orders are published randomly and at various intervals of time. The orders are sorted as the priority as soon as they are received. Then we process the orders according to the priority order (Red- Yellow- Green) and place the corresponding packages on the conveyor. Here, Logical Camera_1 placed at the top of the conveyor belt registers the package being placed as well but we have not made much use of this camera for our code. Once the package is placed on the conveyor belt by UR5_1 the \u2018Order Dispatched\u2019 sheet is updated and an Email of the order being dispatched is sent. This sheet is also a part of the IMS. The email address used for this task is the team ID account we have created for E-Yantra. The package placed on the conveyor belt is then picked by UR5_2 once it comes into the field of vision of Logical Camera_2. As soon as this camera registers the package arriving the conveyor belt is stopped till UR5_2 has picked up the package. It then gets sorted into its respective bin followed by another email being sent of the order getting delivered. Additionally, the \u2018Order Shipped\u2019 sheet is updated in the IMS which keeps track of all the orders shipped and their time. The WMS sheet is update simultaneously throughout the task which acts as a Summary sheet of the IMS also called the Dashboard. This used to reflect on the real-time values.","title":"Implementation"},{"location":"#rqt-graph","text":"","title":"RQT Graph"}]}